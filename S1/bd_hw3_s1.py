# -*- coding: utf-8 -*-
"""BD HW3 S1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W3S8Ewc6qMG_EM7gYi47_rFCXSKbtyQn

# Step 1 (Basic instrucitons)

## Environment Setup

### Install requirements
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz
!tar xf spark-3.1.1-bin-hadoop3.2.tgz
!pip install -q findspark

"""### Set environment variables"""

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.1-bin-hadoop3.2"

"""### Import libraries"""

import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()
spark.conf.set("spark.sql.repl.eagerEval.enabled", True) # Property used to format output tables better
spark

import re

"""### Get spark context"""

sc = spark.sparkContext

"""## Part 1

### Read input file
"""

input_file_path = "/content/input.txt"
input_file = sc.textFile(input_file_path)
print(input_file.first())

"""### Count number of words"""

wordsRDD = input_file.flatMap(lambda line: line.split(" "))
print("First 5 words:")
print(wordsRDD.take(5))
words_count = wordsRDD.count()
print("Words count: {}".format(words_count))

"""### Count each word repeat and save output in `words_count.txt`"""

print("Words repeat count:")
words_repeation = wordsRDD.countByValue()
print(words_repeation)
output_file_name = "words_count.txt"
with open(output_file_name, "w") as output_file:
  for word, count in words_repeation.items():
    new_line = f"{word}: {count}\n"
    output_file.write(new_line)
  output_file.close()

"""### Remove punctuation marks and repeat actions"""

clean_wordsRDD = (input_file
                  .flatMap(lambda line: re.split('[ ?!.,:;\t()]', line))
                  .filter(lambda word: word != ''))
print("First 5 words:")
print(clean_wordsRDD.take(5))
clean_words_count = clean_wordsRDD.count()
print("Words count: {}".format(clean_words_count))

print("Words repeat count:")
clean_words_repeation = clean_wordsRDD.countByValue()
print(clean_words_repeation)
output_file_name = "clean_words_count.txt"
with open(output_file_name, "w") as output_file:
  for word, count in clean_words_repeation.items():
    new_line = f"{word}: {count}\n"
    output_file.write(new_line)
  output_file.close()

"""## Part 2

### Find words count that start with "m/M"
"""

words_with_m = clean_wordsRDD.filter(lambda word: word[0] in ["m", "M"])
print("First 5 words:")
print(words_with_m.take(5))
words_with_m_count = words_with_m.count()
print("Words starts with m count: {}".format(words_with_m_count))

"""## Part 3

### Count words with 5 chars
"""

five_char_words = clean_wordsRDD.filter(lambda word: len(word) == 5)
print("First 5 words:")
print(five_char_words.take(5))
five_char_words_count = five_char_words.count()
print("Five char words: {}".format(five_char_words_count))

"""### Remove words starts with vowels"""

vowels = ["a", "u", "i", "o", "u"]
reduced_five_words = five_char_words.filter(lambda word: word.lower()[0] not in vowels)
print("First 5 words:")
print(reduced_five_words.take(5))
reduced_five_words_count = reduced_five_words.count()
print("Five char words without vowel start: {}".format(reduced_five_words_count))
print("Sorted result:")
print(reduced_five_words.takeOrdered(reduced_five_words_count))

"""## Part 4

### Find stop words
"""

sorted_repeation = sorted(clean_words_repeation.items(), key=lambda item: item[1], reverse=True)
ten_percent_count = len(sorted_repeation) // 10
stop_words_with_count = sorted_repeation[:ten_percent_count]
stop_words = [stop_word for stop_word, _ in stop_words_with_count]
print("First 10 stop words:")
print(stop_words[:10])

"""### Remove stopwords and non alpha numberic chars"""

!rm -r removed_stop_words
def clean_line(line):
  cleaned_line = ""
  for word in line.split():
    if word not in stop_words:
      cleaned_line += word
      cleaned_line += " "
  cleaned_line = re.sub("[^0-9a-zA-Z]+", " ", cleaned_line)
  return cleaned_line

clean_lines = (input_file.flatMap(lambda line: line.split("."))
               .map(clean_line))
clean_lines.collect()
removed_stop_words_file_name = "removed_stop_words"
clean_lines.coalesce(1).saveAsTextFile(removed_stop_words_file_name)

"""## Part 5

### Find bigrams
"""

bigrams = input_file.flatMap(lambda line: line.split(".")) \
                   .map(lambda line: line.strip().split(" ")) \
                   .flatMap(lambda xs: (tuple(x) for x in zip(xs, xs[1:])))
print("First five bigrams:")
print(bigrams.take(5))

"""### Calculate frequencies and sort them"""

bigrams_frequencies = bigrams.countByValue()
sorted_bigram_frequencies = sorted(bigrams_frequencies.items(), key=lambda item: item[1], reverse=True)
print("Bigrams: (Sorted by frequency)")
for word, repeat in sorted_bigram_frequencies:
  print(f"{word}: {repeat}")